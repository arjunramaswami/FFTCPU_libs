# FFTW

This folder contains the code to execute 3d FFT using FFTW. Currently executes
single threaded, multi threaded configurations on single and double precision
complex numbers.

Link to the official FFTW [website](http://www.fftw.org/).

## Builds

### Prerequisites

- easybuild FFTW `module load numlib/FFTW`
- C compiler that implements OpenMPI (tested with gcc 8.3.0)

### Targets

1. Single precision single threaded FFTW

   `make` and `make sp` : Creates an executable named `host_sp` in the FFTW directory

2. For double precision single threaded FFTW

   `make dp` : Creates an executable named `host_dp` in the FFTW directory

3. Multi threaded FFTW (always uses double precision)

   `make omp` : Creates an executable named `host_omp` in the FFTW directory

Compiling with DEBUG macro set say, `make DEBUG=1 omp`, prints data input to
  FFTW

## Execution

Running the program with `-h` to print the options available.
Options:

```bash
  -m : FFT 1st Dim Size
  -n : FFT 2nd Dim Size
  -p : FFT 3rd Dim Size

  -i : Number of iterations of the FFT computation

  -t : number of threads in a multithreaded execution
```

### Example multithreaded execution

```bash
  module load numlib/FFTW
  make omp
  ./host_omp -m 256 -n 256 -p 256 -t 40
```

## Interpreting Results

The output shows configuration of execution and the series of steps the program
executes followed by the consolidation of some performance metrics such as:

```bash
Number of runs : 100

FFT Size    Total Runtime(ms)   Avg Runtime(ms)     Throughput(GFLOPS)
   32          30.051               0.300               23.51
```

- FFT Size is the size of the 3d FFT
- Total Runtime (milliseconds) : total amount of time to execute the given
  number of iterations.
- Avg Runtime (milliseconds) : average runtime for a single iteration of execution i.e.,
  total runtime by the number of iterations
- Throughput (GFLOPS): Calculated by *3 * 5 * N * logN / (time for one FFT)* as described
  by the [FFTW Benchmark Methodology](http://www.fftw.org/speed/method.html).
  This is not the actual flop count rather an asymptotic measurement using the
  radix-2 Cooley Tukey algorithm.

### Important Points

- Runtime only measures the walltime of the FFTW execution, not the
  initialization and plan creation. Measured using `clock_gettime` to provide
  nanosecond resolution.
- Iterations are made on the same input data. Input data is [0, N^3 - 1] where
  N is the number of data points in a dimension.

## Results

### Best Runtime and Throughput

This is required to compare each FFT size with other FFT libraries and implementations.

| FFT3d Size | Best Runtime (ms) | Throughput (GFLOPS) |
|:----------:|:-----------------:|:-------------------:|
|     16     |   0.022           |     11.13           |
|     32     |   0.054           |     45.38           |
|     64     |   0.234           |    100.55           |
|     128    |   1.779           |    123.77           |
|     256    |    72.462         |     27.78           |

### Speedup with Multithreading

Maximum speedup obtained per size when strong scaling to 40 threads. 

| FFT3d Size | Max Speedup |
|:----------:|:-----------:|
|     16     |     1.0     |
|     32     |     3.74    |
|     64     |     13.14   |
|     128    |     21.33   |
|     256    |     12.03   |

#### Notes

- Better Speedup with increase in FFT size i.e., more data
- Could 256<sup>3</sup> offer better speedup with more threads?
- Can one estimate the maximum speedup possible?

### Details on execution

The bash file `omp_fftw_run.sh` can be used to execute on NOCTUA cluster :
```
sbatch omp_fftw_run.sh <array of sizes of fft3d>

sbatch omp_fftw_run.sh 16 32 64
```

1. loads `gcc/8.3.0` and `numlib/FFTW`

2. Sets openmp thread affinity env variables

3. Executes the application using srun on the same node from 1 to 40 threads
one after another and saves the output in distinct reports.

The bash file `create_csv.sh` can be used to create a csv output from the reports generated by the above bash file.

`./create_csv.sh <generated_report> <output.csv>`

## Configuring FFTW with OpenMP

Steps to configure multithreaded execution of FFTW with OpenMPI

### Code Modification

Initialize the environment:

  ```C
  #include<omp.h>
  int fftw_init_threads(void);
  ```

Make the plan with the necessary number of threads to execute

  ```C
  void fftw_plan_with_nthreads(int nthreads);
  ```

Execute with the normal API call

  ```C
  fftw_execute(plan)
  ```

Cleanup plan and threads after execution

  ```C
  fftw_destroy_plan()
  void fftw_cleanup_threads(void);
  ```

#### FFTW API for multithreading works only with double precision

- Creating a single precision plan after initializing threads produces single
   threaded outcomes.
- Creating fftwf alternatives throw linker error due to lack of such
   functionalities.

### Compilation

To compile with OpenMPI, link this additional flag `-lfftw3_omp` along with
`-fopenmp` other than the regular `fftw` flags. These are added to the makefile.

## Note

Execution is thread-safe but not plan creation and destruction, therefore use a
single thread for the latter.

## TODO

Pin OpenMP threads using environment variables as opposed to using `srun bind`.
There is also an environment variable to output the pinning results at runtime.

[Link1](http://pages.tacc.utexas.edu/~eijkhout/pcse/html/omp-affinity.html)

[Link2](https://groups.uni-paderborn.de/pc2/lectures/hpccourse03/material/hpcadv.pdf)

